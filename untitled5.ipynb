{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/L03k2hVoSVxXTP/4zAmJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henriquecm02/henriquecm02/blob/main/untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Configura√ß√µes iniciais\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=\"INSIRA_SUA_API_KEY\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "m0FN66aHLuef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Listando os modelos dispon√≠veis\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "id": "sFWyBwM7Lw9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "TP517jHuMcYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"safety_settings={\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "    }\"\"\""
      ],
      "metadata": {
        "id": "Vh7NnB-1MiJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                                  generation_config=generation_config,\n",
        "                                  safety_settings=safety_settings,)"
      ],
      "metadata": {
        "id": "7yB-LqPTMndK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Que empresa criou o modelo de IA Gemini?\")\n",
        "response.text"
      ],
      "metadata": {
        "id": "xutt6zgJMtGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = {\n",
        "1 : \"Professor de Seguran√ßa da Informa√ß√£o para leigos e Iniciantes\",\n",
        "2 : \"Engenheiro de Software com foco em seguran√ßa\",\n",
        "3 : \"Engenheiro de Ciberseguran√ßa S√™nior\",\n",
        "}"
      ],
      "metadata": {
        "id": "-Q6RXa1PamxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_instructions = {\n",
        "    1: {\n",
        "        \"persona\": \"Professor de Seguran√ßa da Informa√ß√£o\",\n",
        "        \"tone\": \"informative\",\n",
        "        \"style\": \"friendly\"\n",
        "    },\n",
        "    2: {\n",
        "        \"persona\": \"Engenheiro de Software\",\n",
        "        \"tone\": \"technical\",\n",
        "        \"style\": \"professional\"\n",
        "    },\n",
        "    3: {\n",
        "        \"persona\": \"Especialista em Seguran√ßa da Informa√ß√£o\",\n",
        "        \"tone\": \"authoritative\",\n",
        "        \"style\": \"formal\"\n",
        "    }\n",
        "}\n",
        "conteudos = {\n",
        " 1 : \"O que √© Seguran√ßa da Informa√ß√£o?\",\n",
        "\n",
        "2 : \"T√©cnicas de Preven√ß√£o de um ataque cibern√©tico?\",\n",
        "\n",
        "3 :  \"Principais Amea√ßas Cibern√©ticas Atuais.\",\n",
        "\n",
        "4 : \"Como Agir Caso Sofra Um Ataque Cibern√©tico?\",\n",
        "\n",
        "5 : \"Como Funciona a Legisla√ß√£o Contra Crimes Cibern√©tico?\",\n",
        "}"
      ],
      "metadata": {
        "id": "jF8tOafP3-oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])\n",
        "\n",
        "reconhecimento = input(' Ol√°! Bem Vindo(a) ao S1.üö´.S! Queremos mwuito te auxiliar, ent√£o por gentileza nos indique logo abaixo qual a categoria de usu√°rio voc√™ se enquadra:\\n 1- Usu√°rios Convencionais em busca de orienta√ß√µes e solu√ß√µes inteligentes sobre Seguran√ßa da Informa√ß√£o.\\n 2- Desenvolvedores e Profissionais de TI, buscando avaliar o n√≠vel de seguran√ßa de seus c√≥digos.\\n 3- Profissionais de Seguran√ßa da Informa√ß√£o e Telecomunica√ß√µes, buscando solu√ß√µes avan√ßadas.\\n Digite o n√∫mero da op√ß√£o desejada.\\n')\n",
        "\n",
        "if reconhecimento == 1 :\n",
        "'''\n",
        "Para come√ßar, saiba que a √°rea da seguran√ßa da informa√ß√£o √© uma √°rea muito ampla\n",
        "e demanda a integra√ß√£o de conhecimentos em diversas √°reas da computa√ß√£o. Por esse\n",
        "motivo essa √°rea destinada a pessoas iniciantes ou leigas no assunto conta com\n",
        "prompts prontos e direcionados a conte√∫dos b√°sicos de seguran√ßa da informa√ß√£o ge-\n",
        "rados pelo Gemini.\n",
        "Basta selecionar a numera√ß√£o associada ao conte√∫do abaixo que deseja consumir e\n",
        "ele estar√° dispon√≠vel imediatamente. Aproveite!\n",
        "\n",
        "1- O que √© Seguran√ßa da Informa√ß√£o?\n",
        "\n",
        "2- T√©cnicas de Preven√ß√£o de um ataque cibern√©tico?\n",
        "\n",
        "3- Principais Amea√ßas Cibern√©ticas Atuais.\n",
        "\n",
        "4- Como Agir Caso Sofra Um Ataque Cibern√©tico?\n",
        "\n",
        "5- Como Funciona a Legisla√ß√£o Contra Crimes Cibern√©tico?\n",
        "\n",
        "'''\n",
        "  prompt = input('Com o que podemos auxili√°-lo(a): ')\n",
        "  if prompt == 1:\n",
        "    response = chat.send_message(conteudo[1])\n",
        "    print(\"resposta:\", response.text,'\\n\\n')\n",
        "  if prompt == 2:\n",
        "    response = chat.send_message(conteudo[2])\n",
        "    print(\"resposta:\", response.text,'\\n\\n')\n",
        "  if prompt == 3:\n",
        "    response = chat.send_message(conteudo[3])\n",
        "    print(\"resposta:\", response.text,'\\n\\n')\n",
        "  if prompt == 4:\n",
        "    response = chat.send_message(conteudo[4])\n",
        "    print(\"resposta:\", response.text,'\\n\\n')\n",
        "  if prompt == 5:\n",
        "    response = chat.send_message(conteudo[5])\n",
        "    print(\"resposta:\", response.text,'\\n\\n')\n",
        "   # Chamar System Instruction\n",
        "  system_instruction = system_instructions[reconhecimento]\n",
        "  while prompt != \"fim\":\n",
        "    response = chat.send_message(prompt, system_instruction=system_instruction)\n",
        "    print(\"Resposta:\", response.text, '\\n\\n')\n",
        "    prompt = input('Com o que podemos auxili√°-lo(a): ')\n",
        "    if prompt == 1:\n",
        "      response = chat.send_message(conteudo[1])\n",
        "      print(\"resposta:\", response.text,'\\n\\n')\n",
        "    if prompt == 2:\n",
        "      response = chat.send_message(conteudo[2])\n",
        "      print(\"resposta:\", response.text,'\\n\\n')\n",
        "    if prompt == 3:\n",
        "      response = chat.send_message(conteudo[3])\n",
        "      print(\"resposta:\", response.text,'\\n\\n')\n",
        "    if prompt == 4:\n",
        "      response = chat.send_message(conteudo[4])\n",
        "      print(\"resposta:\", response.text,'\\n\\n')\n",
        "    if prompt == 5:\n",
        "      response = chat.send_message(conteudo[5])\n",
        "      print(\"resposta:\", response.text,'\\n\\n')"
      ],
      "metadata": {
        "id": "TL7riPlhM2PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elif reconhecimento == 2 :\n",
        "'''\n",
        "Ol√° DEV </>, bem vindo ao nosso ambiente de integra√ß√£o entre ciberseguran√ßa e\n",
        "desenvolvimento, aqui faremos um colab rumo a mitiga√ß√£o de falhas de seguran√ßa\n",
        "em sistemas, automa√ß√£o de testes de seguran√ßa e tarefas repetitivas relacionadas.\n",
        "A utiliza√ß√£o √© muito intuitiva, basta disponibilizar o c√≥digo para an√°lise, atra-\n",
        "v√©s de texto ou arquivo e utilizar as t√©cnicas de engenharia de prompt est√£o dis-\n",
        "ponibilizadas no texto abaixo:\n",
        "\n",
        "As t√©cnicas de engenharia de prompt s√£o um conjunto de m√©todos usados para melhorar\n",
        " a comunica√ß√£o entre humanos e modelos de linguagem grandes (LLMs) como eu. Ao usar\n",
        "essas t√©cnicas, os usu√°rios podem direcionar os LLMs para realizar tarefas espec√≠ficas\n",
        "e gerar resultados mais relevantes e precisos.\n",
        "Algumas das principais t√©cnicas de engenharia de prompt incluem:\n",
        "1. Prompting com cadeia de pensamento: Essa t√©cnica envolve dividir uma tarefa complexa\n",
        "em etapas menores e mais gerenci√°veis. Cada etapa √© ent√£o descrita em um prompt separado,\n",
        "o que ajuda o LLM a entender melhor o que precisa ser feito.\n",
        "Exemplo:\n",
        " * Prompt 1: Resumir o artigo \"A intelig√™ncia artificial √© uma amea√ßa √† humanidade?\"\n",
        " * Prompt 2: Identificar os principais argumentos do artigo.\n",
        " * Prompt 3: Avaliar a for√ßa dos argumentos do artigo.\n",
        "2. Prompting da √°rvore de pensamento (ToT): Essa t√©cnica envolve estruturar o prompt\n",
        "como uma √°rvore, com o objetivo principal no topo e as subtarefas ramificando-se a partir dele.\n",
        "Isso pode ajudar o LLM a organizar seus pensamentos e seguir um fluxo l√≥gico.\n",
        "Exemplo:\n",
        "Escrever um poema sobre o amor.\n",
        "\n",
        "* Tema: amor\n",
        "* T√≥picos:\n",
        "    * Alegria\n",
        "    * Tristeza\n",
        "    * Perda\n",
        "    * Saudade\n",
        "\n",
        "3. Prompting mai√™utico: Essa t√©cnica se baseia no m√©todo socr√°tico de questionamento para guiar o LLM a chegar √† sua pr√≥pria conclus√£o. O prompt faz uma s√©rie de perguntas ao LLM, o que o ajuda a explorar o t√≥pico e desenvolver seu pr√≥prio entendimento.\n",
        "Exemplo:\n",
        " * O que voc√™ acha que √© amor?\n",
        " * Quais s√£o as diferentes formas de amor?\n",
        " * Qual √© a import√¢ncia do amor em nossas vidas?\n",
        "4. Prompting baseado na complexidade: Essa t√©cnica envolve ajustar o n√≠vel de complexidade do prompt de acordo com as capacidades do LLM. Para LLMs mais b√°sicos, os prompts devem ser mais simples e diretos. Para LLMs mais avan√ßados, os prompts podem ser mais complexos e abrangentes.\n",
        "Exemplo:\n",
        " * Prompt para LLM b√°sico: Escrever uma frase sobre o amor.\n",
        " * Prompt para LLM avan√ßado: Escrever um ensaio sobre a hist√≥ria da filosofia do amor.\n",
        "5. Prompting de conhecimento gerado: Essa t√©cnica envolve usar o conhecimento do LLM para gerar prompts mais eficazes. O LLM pode ser usado para identificar palavras-chave, conceitos e rela√ß√µes relevantes para o t√≥pico em quest√£o. Essa informa√ß√£o pode ent√£o ser usada para criar prompts mais direcionados e precisos.\n",
        "Exemplo:\n",
        "O usu√°rio deseja escrever um poema sobre a natureza. O LLM pode ser usado para gerar uma lista de palavras-chave relacionadas √† natureza, como \"√°rvores\", \"flores\", \"animais\" e \"montanhas\". Essa lista pode ent√£o ser usada para criar um prompt como:\n",
        "Escrever um poema que use as seguintes palavras-chave: √°rvores, flores, animais e montanhas.\n",
        "Ao usar essas e outras t√©cnicas de engenharia de prompt, os usu√°rios podem se comunicar mais efetivamente com LLMs e obter resultados mais satisfat√≥rios. As t√©cnicas de engenharia de prompt est√£o em constante evolu√ß√£o √† medida que os LLMs se tornam mais sofisticados, e √© importante que os usu√°rios se mantenham atualizados sobre as √∫ltimas pr√°ticas recomendadas.\n",
        "\n",
        "\n",
        "'''\n",
        "  prompt = input(': ')\n",
        "#Chamar System Instruction\n",
        "  system_instruction = system_instructions[reconhecimento]\n",
        "  while prompt != \"fim\":\n",
        "    response = chat.send_message(prompt, system_instruction=system_instruction)\n",
        "    print(\"Resposta:\", response.text, '\\n\\n')\n",
        "    prompt = input('Esperando prompt: ')"
      ],
      "metadata": {
        "id": "wCb39ToxGZt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elif reconhecimento == 3 :\n",
        "  prompt = input('Esperando prompt: ')\n",
        "#Chamar System Instruction\n",
        "  system_instruction = system_instructions[reconhecimento]\n",
        "  while prompt != \"fim\":\n",
        "    response = chat.send_message(prompt, system_instruction=system_instruction)\n",
        "    print(\"Resposta:\", response.text, '\\n\\n')\n",
        "    prompt = input('Esperando prompt: ')\n",
        "\n",
        "Else:\n",
        "  Print(\"** Entrada Invalida! **\")"
      ],
      "metadata": {
        "id": "ZBEgNLdAGoqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Chat.history"
      ],
      "metadata": {
        "id": "zgPzD7yBND20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LHudpaCdNN9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}